{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import glob, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 200\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "plt.rc('font', size=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IOT Devices\n",
    "\n",
    "The dataset has been extracted at `ROOT_PATH`, containing the data for each IOT device. There are 9 devices in total. There are folders for each IOT device containing `benign_traffic.csv` and further two folders for `gafgyt_attacks` and `mirai_attacks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = r'/mnt/data/khiz/dataset/00442'\n",
    "\n",
    "IOT_DEVS = [ 'Danmini_Doorbell',\n",
    "             'Ecobee_Thermostat',\n",
    "#              'Ennio_Doorbell',\n",
    "#              'B120N10_Baby_Mon',\n",
    "#              '737E_Security_Cam',\n",
    "#              '838_Security_Cam',\n",
    "#              'Samsung_Webcam',\n",
    "#              '1002_Security_Cam',\n",
    "#              '1003_Security_Cam'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths to CSVs\n",
    "We create a python dictionary that contains all the paths to the CSVs for the respective IOT devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Danmini_Doorbell]\n",
      "   benign_traffic.csv\n",
      "   gafgyt :  ['combo.csv', 'junk.csv', 'scan.csv', 'tcp.csv', 'udp.csv']\n",
      "   mirai :  ['ack.csv', 'scan.csv', 'syn.csv', 'udp.csv', 'udpplain.csv']\n",
      "[Ecobee_Thermostat]\n",
      "   benign_traffic.csv\n",
      "   gafgyt :  ['combo.csv', 'junk.csv', 'scan.csv', 'tcp.csv', 'udp.csv']\n",
      "   mirai :  ['ack.csv', 'scan.csv', 'syn.csv', 'udp.csv', 'udpplain.csv']\n"
     ]
    }
   ],
   "source": [
    "PATHS_DICT = {}\n",
    "\n",
    "for i in IOT_DEVS:\n",
    "    PATHS_DICT[i] = {}\n",
    "    print('[' + i + ']')\n",
    "    iot_dir = os.path.join(ROOT_PATH, i)\n",
    "    PATHS_DICT[i]['benign'] = os.path.join(iot_dir, 'benign_traffic.csv')\n",
    "    print('  ', 'benign_traffic.csv')\n",
    "    attacks = [ d for d in os.listdir(iot_dir)\n",
    "                   if os.path.isdir( os.path.join(iot_dir, d)) ]\n",
    "    for attack in attacks:\n",
    "        attack_name = attack.split('_')[0]\n",
    "        \n",
    "        PATHS_DICT[i][attack_name] = {}\n",
    "        attack_dir = os.path.join(iot_dir, attack)\n",
    "        types = [ f for f in os.listdir(attack_dir)\n",
    "                   if os.path.isfile( os.path.join(attack_dir, f)) ]\n",
    "        print('  ', attack_name, ': ', types)\n",
    "        for t in types:\n",
    "            type_name = t.split('.')[0]\n",
    "            PATHS_DICT[i][attack_name][type_name] = os.path.join(attack_dir,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CSVs into Pandas\n",
    "We will create pandas dataframe for each botnet attack on each IOT device. For each datafram we will combine the attack traffic with the benign traffic add the following two columns:\n",
    "- `traffic_type` : benign or attack (0 or 1)\n",
    "- `attack_type`  : type of attack e.g, ack, scan etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbaiot_dict = {}\n",
    "for iot_dev in PATHS_DICT:\n",
    "    nbaiot_dict[iot_dev] = {}\n",
    "    b_df = pd.read_csv(PATHS_DICT[iot_dev]['benign'])\n",
    "    b_df['traffic_type'] = 'benign'\n",
    "    b_df['attack_type'] = 'benign'\n",
    "    #nbaiot_dict[iot_dev] = nbaiot_dict[iot_dev].append(df)\n",
    "    for botnet in [ b for b in PATHS_DICT[iot_dev] if b != 'benign']:\n",
    "        nbaiot_dict[iot_dev][botnet] = pd.DataFrame()\n",
    "        nbaiot_dict[iot_dev][botnet] = nbaiot_dict[iot_dev][botnet].append(b_df)\n",
    "        for attack in PATHS_DICT[iot_dev][botnet]:\n",
    "            a_df = pd.read_csv(PATHS_DICT[iot_dev][botnet][attack])\n",
    "            a_df['traffic_type'] = 'attack'\n",
    "            a_df['attack_type'] = attack\n",
    "            nbaiot_dict[iot_dev][botnet] = nbaiot_dict[iot_dev][botnet].append(a_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Danmini_Doorbell\n",
      "   gafgyt : <benign+attack>\n",
      "   mirai : <benign+attack>\n",
      "Ecobee_Thermostat\n",
      "   gafgyt : <benign+attack>\n",
      "   mirai : <benign+attack>\n"
     ]
    }
   ],
   "source": [
    "for k in nbaiot_dict:\n",
    "    print(k)\n",
    "    for b in nbaiot_dict[k]:\n",
    "        print('  ',b,':','<benign+attack>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre processing\n",
    "Convert the target column `traffic_type` to integer 0 = benigh, 1 = attack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dev in nbaiot_dict:\n",
    "    for botnet in nbaiot_dict[dev]:\n",
    "        nbaiot = nbaiot_dict[dev][botnet]\n",
    "\n",
    "        nbaiot.loc[ nbaiot['traffic_type']=='attack','traffic_type' ]=1\n",
    "        nbaiot.loc[ nbaiot['traffic_type']=='benign','traffic_type' ]=0\n",
    "        nbaiot['traffic_type'] = nbaiot['traffic_type'].astype(int)\n",
    "        \n",
    "        nbaiot_dict[dev][botnet] = nbaiot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers and training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classfiers = {\n",
    "    'KNN' : KNeighborsClassifier(),\n",
    "    'RFR' : RandomForestClassifier(),\n",
    "    'DTR' : DecisionTreeClassifier(),\n",
    "    'ADB' : AdaBoostClassifier(),\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "def train_test_report( X_train, X_test, y_train, y_test, avg='macro avg' ):\n",
    "\n",
    "    result = []\n",
    "    for clf_name in classfiers:\n",
    "        clf = classfiers[clf_name]\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_preds = clf.predict(X_test)\n",
    "        \n",
    "        clrp = classification_report(y_test, y_preds, output_dict=True)\n",
    "        conf_mat = confusion_matrix(y_test, y_preds)\n",
    "        fp = conf_mat[0][1]\n",
    "        fn = conf_mat[1][0]\n",
    "        \n",
    "        result.append([\n",
    "            clf_name,\n",
    "            clrp['accuracy'],\n",
    "            clrp[avg]['precision'],\n",
    "            clrp[avg]['recall'],\n",
    "            clrp[avg]['f1-score'],\n",
    "            fp,\n",
    "            fn\n",
    "        ])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DEV= Danmini_Doorbell\n",
      "  TEST_DEV= Danmini_Doorbell\n",
      "================ Danmini_Doorbell/Danmini_Doorbell/mirai ================\n",
      "['KNN', 0.9992232572457984, 0.9964852265685675, 0.9976053314324629, 0.9970445351315236, 212, 333]\n",
      "['RFR', 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
      "['DTR', 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
      "['ADB', 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
      "================ Danmini_Doorbell/Danmini_Doorbell/gafgyt ================\n",
      "['KNN', 0.999019656033075, 0.9973456990042966, 0.9984712501152531, 0.9979075575112704, 113, 246]\n",
      "['RFR', 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
      "['DTR', 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
      "['ADB', 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
      "  TEST_DEV= Ecobee_Thermostat\n",
      "================ Danmini_Doorbell/Ecobee_Thermostat/mirai ================\n",
      "['KNN', 0.9952517487044166, 0.9263135696352905, 0.986901947611508, 0.9544755594532957, 287, 2207]\n",
      "['RFR', 0.9999828651717481, 0.9999540391702109, 0.9996939828919046, 0.9998239753802531, 8, 1]\n",
      "['DTR', 0.9999504993850501, 0.9991214142163916, 0.9998631545958616, 0.999491994165026, 3, 23]\n",
      "['ADB', 0.9999980961301942, 0.9999618728076864, 0.9999990236911115, 0.9999804475220533, 0, 1]\n",
      "================ Danmini_Doorbell/Ecobee_Thermostat/gafgyt ================\n",
      "['KNN', 0.9986810525632986, 0.9906545523961872, 0.9924103186936655, 0.9915307217811227, 189, 238]\n",
      "['RFR', 0.9991505607843258, 0.9995577427188369, 0.9895142225272631, 0.9944803264470665, 275, 0]\n",
      "['DTR', 0.9804690757792447, 0.9900253349865753, 0.7589033783268513, 0.8361170191225353, 6323, 0]\n",
      "['ADB', 0.9999536669518723, 0.9999758566852839, 0.999428048501487, 0.9997017886440659, 15, 0]\n",
      "TRAIN_DEV= Ecobee_Thermostat\n",
      "  TEST_DEV= Danmini_Doorbell\n",
      "================ Ecobee_Thermostat/Danmini_Doorbell/mirai ================\n",
      "['KNN', 0.917578329874809, 0.7290982885504744, 0.9431537588064776, 0.789385276896891, 1341, 56490]\n",
      "['RFR', 0.9911964403803617, 0.9953082061199161, 0.937666505207072, 0.9644044175201354, 6177, 0]\n",
      "['DTR', 0.9914957357535402, 0.9954555407739227, 0.939794986859093, 0.9656872860470032, 5966, 1]\n",
      "['ADB', 0.9999330148450505, 0.9999639651796297, 0.9995257124404617, 0.9997447256330533, 47, 0]\n",
      "================ Ecobee_Thermostat/Danmini_Doorbell/gafgyt ================\n",
      "['KNN', 0.9964663924980475, 0.9973947694795104, 0.9874952478984151, 0.9923736165846457, 1229, 65]\n",
      "['RFR', 0.9937001294381728, 0.9963835250519663, 0.9767195446839428, 0.9862675227493973, 2307, 0]\n",
      "['DTR', 0.9957973555289761, 0.9975816260147271, 0.9844696052312909, 0.9909001852282541, 1539, 0]\n",
      "['ADB', 0.9986755798775526, 0.9992353414161161, 0.9951057560345524, 0.9971582204325037, 485, 0]\n",
      "  TEST_DEV= Ecobee_Thermostat\n",
      "================ Ecobee_Thermostat/Ecobee_Thermostat/mirai ================\n",
      "['KNN', 0.9994364545374929, 0.9973761332102393, 0.9910170254721107, 0.9941750208339513, 234, 62]\n",
      "['RFR', 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
      "['DTR', 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
      "['ADB', 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
      "================ Ecobee_Thermostat/Ecobee_Thermostat/gafgyt ================\n",
      "['KNN', 0.9991134943458236, 0.9973174917692822, 0.9912478894002175, 0.9942623451584621, 227, 60]\n",
      "['RFR', 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
      "['DTR', 1.0, 1.0, 1.0, 1.0, 0, 0]\n",
      "['ADB', 1.0, 1.0, 1.0, 1.0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "all_results = [\n",
    "    ['TRAIN DEVICE', 'TEST DEVICE', 'BOTNET', 'CLASSIFIER', 'ACCURACY', 'PRECISION', 'RECALL', 'F1-SCORE', 'FALSE-P', 'FALSE-N' ]\n",
    "]\n",
    "\n",
    "for train_dev in nbaiot_dict:\n",
    "    print('TRAIN_DEV=',train_dev)\n",
    "    for test_dev in nbaiot_dict:\n",
    "        print('  TEST_DEV=',test_dev)\n",
    "        for botnet in set(nbaiot_dict[test_dev].keys()).intersection(nbaiot_dict[train_dev].keys()):\n",
    "            \n",
    "            print(\"================\", '/'.join([train_dev,test_dev,botnet]), \"================\")\n",
    "            \n",
    "            train_df = nbaiot_dict[train_dev][botnet]\n",
    "            test_df  = nbaiot_dict[test_dev][botnet]\n",
    "            \n",
    "            X_train = train_df.drop([\"attack_type\", \"traffic_type\" ], axis=1)\n",
    "            y_train = train_df['traffic_type']\n",
    "            X_test  = test_df.drop([\"attack_type\", \"traffic_type\" ], axis=1)\n",
    "            y_test  = test_df['traffic_type']\n",
    "            \n",
    "            rep = train_test_report( X_train, X_test, y_train, y_test )\n",
    "            \n",
    "            for r in rep:\n",
    "                print(r)\n",
    "                all_results.append( [train_dev, test_dev, botnet] + r )\n",
    "            \n",
    "# for dev in nbaiot_dict:\n",
    "#     for botnet in nbaiot_dict[dev]:\n",
    "#         nbaiot = nbaiot_dict[dev][botnet]\n",
    "        \n",
    "#         print(\"================\", dev, \"/\", botnet, \"================\")\n",
    "\n",
    "#         X = nbaiot.drop( [\"attack_type\", \"traffic_type\" ], axis=1 )\n",
    "#         y = nbaiot[\"traffic_type\"]\n",
    "\n",
    "#         rep = train_test_report( X, y)\n",
    "#         for r in rep:\n",
    "#             print(r)\n",
    "#             all_results.append( [dev, botnet] + r )\n",
    "\n",
    "#         print(\"================================================================\")\n",
    "#         print(\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df =pd.DataFrame(all_results, index=None)\n",
    "\n",
    "res_df, res_df.columns = res_df[1:] , res_df.iloc[0]\n",
    "\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to csv\n",
    "res_csv = res_df.to_csv(index=False)\n",
    "\n",
    "print(res_csv, file=open('02_results.csv', 'w'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_df = pd.read_csv('04_results.csv')\n",
    "\n",
    "res_df = res_df[['DEVICE', 'BOTNET', 'CLASSIFIER', 'ACCURACY', 'PRECISION', 'FALSE-P', 'FALSE-N' ]]\n",
    "\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.set_index(['DEVICE', 'BOTNET', 'CLASSIFIER'], inplace=True)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df0 = res_df.unstack(level=1)\n",
    "res_df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df1 = res_df0.unstack(level=1)\n",
    "res_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df1.plot(kind='bar')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
